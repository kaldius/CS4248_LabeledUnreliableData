{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2a2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88671693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/zhing/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cff942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6d6f7",
   "metadata": {},
   "source": [
    "Helper functions to produce features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a0c68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_positive_negative(words):\n",
    "    # Use the SentimentIntensityAnalyzer to get sentiment scores for each word\n",
    "    score = sia.polarity_scores(word)\n",
    "    scores_pos = [score['pos'] for word in words]\n",
    "    scores_neg = [score['neg'] for word in words]\n",
    "\n",
    "    # Get the total number of positive words\n",
    "    num_pos_words = sum([1 for score in scores_pos if score > 0])\n",
    "    num_neg_words = sum([1 for score in scores_neg if score > 0])\n",
    "\n",
    "    # Access value with result[0], result[1]\n",
    "    return num_pos_words, num_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fc92887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_positive_followed_by_negative(words):\n",
    "    # Initialize counters\n",
    "    num_positive_followed_by_negative = 0\n",
    "\n",
    "    # Iterate over words in input string\n",
    "    for i, word in enumerate(words):\n",
    "        # If current word is negative any of the previous 5 words are positive\n",
    "        if sia.polarity_scores(word)['compound'] < 0 and any(sia.polarity_scores(w)['compound'] > 0 for w in words[max(0, i-5):i]):\n",
    "            # Increment counter for positive words followed by negative words\n",
    "            num_positive_followed_by_negative += 1\n",
    "\n",
    "    return num_positive_followed_by_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e980b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_proper_nouns(pos_tags):\n",
    "    num_proper_nouns = sum(1 for word, tag in pos_tags if tag == 'NNP')\n",
    "    return num_proper_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2865e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_conjunctions(pos_tags):\n",
    "    num_conjunctions = sum(1 for word, tag in pos_tags if tag == 'CC')\n",
    "    return num_conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8b122ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_superlatives(pos_tags):\n",
    "    num_superlatives = sum(1 for word, tag in pos_tags if tag == \"JJS\")\n",
    "    return num_superlatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca61adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronouns(text):\n",
    "    first_person = len(re.findall(r'\\b(I|me|my|mine|we|us|our|ours)\\b', text, flags=re.IGNORECASE))\n",
    "    second_person = len(re.findall(r'\\b(you|your|yours)\\b', text, flags=re.IGNORECASE))\n",
    "    third_person = len(re.findall(r'\\b(he|him|his|she|her|hers|it|its|they|them|their|theirs)\\b', text, flags=re.IGNORECASE))\n",
    "    # first_person, second_person, third_person = count_pronouns(text)\n",
    "    return first_person, second_person, third_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7d2f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hedges(text):\n",
    "    # Load the list of hedging words from a text file\n",
    "    with open('hedging_words.txt', 'r') as f:\n",
    "        hedging_words = [line.strip() for line in f]\n",
    "\n",
    "    # Use NLTK to tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Count the number of hedging words in the text\n",
    "    num_hedges = sum(1 for word in words if word.lower() in hedging_words)\n",
    "\n",
    "    return num_hedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "567d5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_boosts(text):\n",
    "    # Load the list of hedging words from a text file\n",
    "    with open('boosting_words.txt', 'r') as f:\n",
    "        boosting_words = [line.strip() for line in f]\n",
    "\n",
    "    # Use NLTK to tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Count the number of hedging words in the text\n",
    "    num_boosts = sum(1 for word in words if word.lower() in boosting_words)\n",
    "\n",
    "    return num_boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "259d2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(text):\n",
    "    pattern = r\"\\d{1,3}(,\\d{3})*(\\.\\d+)?\"  # regular expression pattern to match numbers\n",
    "    matches = re.findall(pattern, text)  # find all matches of the pattern in the text\n",
    "    return len(matches)  # return the count of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_quotes(text):\n",
    "    pattern = r\"[\\s][\\p{P}'].+[\\p{P}'][\\p{P}]?\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e41636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    words = text.split()\n",
    "    num_pos_words, num_neg_words = count_positive_negative(words)\n",
    "    num_positive_followed_by_negative = count_positive_followed_by_negative(words)\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    num_proper_nouns = count_proper_nouns(pos_tags)\n",
    "    num_conjunctions = count_conjunctions(pos_tags)\n",
    "    num_superlatives = count_superlatives(pos_tags)\n",
    "    \n",
    "    first_person, second_person, third_person = count_pronouns(text)\n",
    "    num_hedges = count_hedges(text)\n",
    "    num_boosts = count_boosts(text)\n",
    "    num_numbers = count_numbers(text)\n",
    "    num_quotes = count_quotes(text)\n",
    "    \n",
    "    return num_pos_words, num_neg_words, num_positive_followed_by_negative, first_person, second_person, third_person, num_proper_nouns, num_conjunctions, num_superlatives, num_hedges, num_boosts, num_numbers, num_quotes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb10b6a",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ad3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = \"../raw_data/fulltrain.csv\"\n",
    "df_train = pd.read_csv(training_data_filename, names=[\"label\", \"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    y_train.append(row[\"label\"])\n",
    "    text = row[\"document\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
